# 🚗 基于 OrangePi AIpro 和鸿蒙系统的智能网联小车开发

## 一、项目信息

### 1. 项目名称
本项目名称为 **基于 OrangePi AIpro 和鸿蒙系统的智能网联小车开发**。随着无线通信和人工智能技术的快速发展，利用国产开发板及支持鸿蒙系统的移动终端开发智能网联小车，成为了开发者快速利用国产化软硬件技术掌握车联网开发的一种有效手段。本项目使用OrangePi AIpro开发板和高清摄像头搭建智能网联小车，将为智能小车的研究和开发提供重要的实践平台。

### 2. 方案描述
本项目任务主要包括三部分：  

1. 在华为云平台ModelArts上使用Mindyolo，训练目标识别的模型，并将模型在OrangePi AIpro开发板上进行部署，实现对实时视频流的推理。
2. 使用边缘检测算法提取每一帧图像的边缘信息，实现车道线检测、车道偏移计算等辅助控制功能。
3. 开发鸿蒙应用程序实现控制者通过wifi远程控制智能网联小车运动，并将小车采集的视频数据实时通过wifi传输到鸿蒙终端。远程控制者在终端可以实时观看目标检测、车道保持、车道偏移等结果。

### 3. 时间规划
- **第一阶段（2025/7/1 - 2025/7/15）**  
  学习目标识别及车道检测算法，准备数据集与开发环境，熟悉 OrangePi AIpro 部署及鸿蒙开发。  
- **第二阶段（2025/7/16 - 2025/8/16）**  
  实现目标检测、车道检测与偏移量计算，并部署算法至 OrangePi AIpro，测试性能并优化。  
- **第三阶段（2025/8/17 - 2025/9/10）**  
  小车组件组装与控制测试，实现 Wi-Fi 远程控制和视频推流。  
- **第四阶段（2025/9/11 - 2025/9/18）**  
  开发鸿蒙终端应用，实现远程控制。  
- **第五阶段（2025/9/19 - 2025/9/28）**  
  小车功能联调与测试，完成结项报告。

---

## 二、已完成工作

### 1. 目标识别模型训练
- **技术方案**  
  本项目的模型训练基于开源物体检测数据集 COCO2017，使用华为云 ModelArts 训练 MindYOLO 模型。COCO2017 数据集主要用于物体检测任务、关键点检测任务和全景分割任务，共包含训练集 118287 张，验证集 5000 张，80 分类。

  MindSpore 是华为开发的全场景 AI 计算框架，支持端、边、云全场景的 AI 应用开发。MindYOLO 是 MindSpore 生态的一部分，提供了 YOLO 系列算法（YOLOv3/v4/v5/v7/v8/X）实现和优化的统一框架。

- **工作成果**  
  使用 MindYOLO 的 YOLOv5 进行目标识别，主要步骤包括：  
  1. 划分图像为固定网格  
  2. 预测边界框和类别  
  3. 单次前向传递进行预测  
  4. 使用多任务损失函数训练网络  
  5. 非最大抑制去除冗余边界框  

  YOLO 速度快，可实现实时视频处理，模型可部署至边缘计算设备保证高实时性和高准确性。

  ModelArts 使用流程：  
  1. 登录华为云控制台 → 进入 ModelArts → 创建 OBS 桶存储数据集  
  2. 在 JupyterLab 中解压数据集和训练文件 → 执行训练  
  3. 使用 MindYOLO `export` 接口将 ckpt 转为 onnx，再用 ATC 转换为 OM 模型文件  
  4. OM 模型部署至 OrangePi AIpro，实现边缘推理

### 2. 车道线检测
- **技术方案**  
  使用 Canny 边缘检测算法进行车道线检测，主要步骤：  
  1. 灰度化处理  
  2. 高斯滤波降低噪声  
  3. 计算图像梯度（Sobel 算子）  
  4. 非极大值抑制  
  5. 双阈值处理  
  6. 弱边缘与强边缘连接  

- **工作成果**  
  通过灰度化、高斯模糊、Canny 提取边缘，再在感兴趣区域（ROI）内用概率霍夫直线变换检测左右车道线。使用队列平滑处理最近几帧，最终在图像上绘制稳定车道线。

### 3. 车道偏移量计算
- **技术方案**  
  通过左右车道线位置估计车道中心位置，与车辆图像中心点差值即为车道偏移量（负值左偏，正值右偏）。  

- **工作成果**  
  根据偏移量数值决定指令（左微调 AL、右微调 AR、直行 F），通过 UDP 发送给鸿蒙终端。

### 4. OrangePi AIpro 模型部署
- **技术方案**  
  推理流程：  
  1. 输入预处理（letterbox 缩放、BGR→RGB、HWC→CHW、float32）  
  2. 调用 `InferSession.infer()` 推理  
  3. 后处理（解析框坐标、NMS、映射回原图）  
  4. 可视化（PIL 绘制边框和标签）  
  5. 结果发送（JSON via UDP）

  模型转换：MindYOLO ckpt → onnx → ATC → OM。  
  YoloV5 类继承基础 Model 类，实现前处理、推理、后处理等方法。NPU 运行低延迟，适合边缘计算。

- **工作成果**  
  成功识别行人和小汽车，并通过界面显示 UDP 信息，实现实时反馈。

### 5. 基于鸿蒙的 UI 界面开发
- **技术方案**  
  使用 DevEco Studio + ArkTS 语言开发上位机界面，ArkTS 支持声明式 UI、状态管理和静态类型，适合高性能 HarmonyOS 应用开发。  

- **工作成果**  
  界面功能模块：  
  1. 运动控制（前进/后退/左转/右转）  
  2. 舵机控制（左右/上下）  
  3. 速度调节（高/中/低）  
  4. 视频回传  
  5. 信息交互（UDP 文字显示）

### 6. 智能网联车构造设计和模拟沙盘
- **技术方案**  
  - 轻量化、模块化车体设计  
  - 双层亚克力车体、舵机调节摄像头、OrangePi AIpro 主控  
  - 四轮差速驱动，麦克纳姆轮，低重心稳定  
  - 沙盘道路用灰色贴纸铺设，放置人形和车辆模型模拟复杂交通环境

- **工作成果**  
  完成小车结构搭建和沙盘模拟实验，验证目标识别、车道线检测及车道保持功能。

---

## 三、遇到的问题及解决方案
1. **MindYOLO 模型 ONNX 导出**  
   - 问题：SiLU 算子不被支持  
   - 解决方案：参考 HiAscend 文档处理 SiLU 算子不支持问题

2. **AscendCL 接口端侧推理**  
   - 问题：未初始化 AscendCL 导致资源错误  
   - 解决方案：调用资源前先初始化 AscendCL，并在推理结束后释放资源

3. **智能车实时视频推流延迟**  
   - 问题：HTTP 请求-响应模式导致延迟高  
   - 解决方案：降低分辨率/帧率，使用局域网，多线程或异步框架共享视频帧

4. **鸿蒙控制界面开发问题**  
   - 问题：ArkTS 框架、网络通信、性能优化适应  
   - 解决方案：熟悉声明式 UI、使用 WebSocket 实时通信、异步解耦界面逻辑

---

## 四、后续工作安排
1. **多传感器融合**  
   - 增加激光雷达用于精确测距和建图  
   - 增加超声波传感器用于近距离障碍物检测

2. **自动驾驶辅助功能**  
   - 自动巡航：激光雷达保持前车距离与速度  
   - 自动刹车/避障：多传感器检测障碍物并计算最优制动策略

3. **智能路径规划与导航**  
   - 全局路径规划（Dijkstra 等算法）  
   - 实时传感器数据调整局部路径，实现动态避障

4. **远程监控与控制**  
   - 搭建小车端与云端通信模块（5G/Wi-Fi）  
   - 实时视频流、状态数据和手动控制界面
