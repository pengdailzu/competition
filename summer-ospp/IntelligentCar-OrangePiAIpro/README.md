# 🚗 基于 OrangePi AIpro 和鸿蒙系统的智能网联小车开发

## 一、项目信息

### 1. 项目名称
本项目名称为 **基于 OrangePi AIpro 和鸿蒙系统的智能网联小车开发**。  
利用国产开发板及支持鸿蒙系统的移动终端开发智能网联小车，成为开发者快速掌握车联网开发的有效手段。本项目使用 OrangePi AIpro 开发板和高清摄像头搭建智能网联小车，为智能小车研究和开发提供实践平台。

### 2. 方案描述
本项目任务主要包括三部分：  
1. 在华为云平台 ModelArts 上使用 MindYOLO 训练目标识别模型，并在 OrangePi AIpro 上部署，实现实时视频流推理。  
2. 使用边缘检测算法提取每帧图像的边缘信息，实现车道线检测、车道偏移计算等辅助控制功能。  
3. 开发鸿蒙应用，实现通过 Wi-Fi 对智能小车远程控制，并实时传输视频数据到终端，显示目标检测和车道保持结果。

### 3. 时间规划
- **第一阶段（2025/7/1 - 2025/7/15）**  
  学习目标识别及车道检测算法，准备数据集与开发环境，熟悉 OrangePi AIpro 部署及鸿蒙开发。  
- **第二阶段（2025/7/16 - 2025/8/16）**  
  实现目标检测、车道检测与偏移量计算，并部署算法至 OrangePi AIpro，测试性能并优化。  
- **第三阶段（2025/8/17 - 2025/9/10）**  
  小车组件组装与控制测试，实现 Wi-Fi 远程控制和视频推流。  
- **第四阶段（2025/9/11 - 2025/9/18）**  
  开发鸿蒙终端应用，实现远程控制。  
- **第五阶段（2025/9/19 - 2025/9/28）**  
  小车功能联调与测试，完成结项报告。

---

## 二、已完成工作

### 1. 目标识别模型训练
- **技术方案**  
  使用 COCO2017 数据集在 ModelArts 上训练 MindYOLO YOLOv5 模型，实现快速、高精度目标识别。  
  YOLO 算法流程包括：划分网格、预测边界框和类别、单次前向传递、损失函数优化、非极大值抑制（NMS）等。  
  YOLO 算法具有高实时性，标准版本每秒处理约 45 帧，极速版本可达 150 帧。

- **工作成果**  
  在 ModelArts 上完成数据准备、训练、ONNX 转换，并使用 ATC 工具生成适用于 Ascend NPU 的 OM 模型。  
  模型可在 OrangePi AIpro 上进行实时推理，实现边缘计算目标检测。

### 2. 车道线检测
- **技术方案**  
  使用 Canny 边缘检测算法检测图像边缘，结合 ROI（感兴趣区域）和霍夫直线变换识别左右车道线。  
  算法步骤：灰度化、高斯滤波、梯度计算、非极大值抑制、双阈值处理、边缘连接。

- **工作成果**  
  实现车道线检测和图像平滑处理，在灰色道路上标记出左右车道线，保证检测稳定性。

### 3. 车道偏移量计算
- **技术方案**  
  根据左右车道线位置，计算车道中心与车辆中心差值作为偏移量，生成转向指令（左/右微调或直行）。

- **工作成果**  
  实现偏移量计算并通过 UDP 将指令发送到鸿蒙终端，保证车辆按车道行驶。

### 4. OrangePi AIpro 模型部署
- **技术方案**  
  模型输入预处理：缩放、RGB 转换、张量化；模型推理：调用 InferSession，输出候选框；后处理：NMS、坐标映射；可视化：绘制边界框与标签。  
  使用 AscendCL 接口管理资源，确保 NPU 推理高效、低延迟。

- **工作成果**  
  部署 YOLOv5 OM 模型，成功实现实时目标识别，并在界面显示检测结果与通信数据。

### 5. 基于鸿蒙的 UI 界面开发
- **技术方案**  
  使用 DevEco Studio 和 ArkTS 开发上位机控制界面，支持运动控制、舵机调节、速度调节、视频回传、信息交互等模块。  

- **工作成果**  
  界面布局简洁直观，功能模块清晰，实现对小车全方位控制和实时信息展示。

### 6. 智能网联车构造设计和模拟沙盘
- **技术方案**  
  小车采用轻量化、模块化设计，双层亚克力车体、舵机可调摄像头、四轮差速驱动、麦克纳木轮，保证稳定性与扩展性。  
  沙盘模拟道路场景，布置人形与车辆模型测试小车感知与控制能力。

- **工作成果**  
  完成智能车结构搭建和沙盘模拟实验，验证目标识别、车道线检测及车道保持功能。

---

## 三、遇到的问题及解决方案
1. **MindYOLO 模型 ONNX 导出**  
   - 问题：SiLU 算子不被支持。  
   - 解决方案：当使用mindyolo开发套件将训练好的ckpt文件转为onnx等模型文件的时候，可能会遇到Mindspore不支持SiLU算子的情况，这个时候可以参考https://www.hiascend.com/document/detail/zh/Atlas200IDKA2DeveloperKit/23.0.RC2/Appendices/ttmutat/atctool_errorcode_0170.html。。

2. **AscendCL 接口端侧推理**  
   - 问题：未初始化 AscendCL 会导致资源错误。  
   - 解决方案：在调用AscendCL相关资源时，必须先初始化AscendCL，否则可能会导致后续系统内部资源初始化出错。读入图片，调用model.infer进行推理，其中包含数据的前处理、输入数据集结构的创建、推理、将推理结果转换为numpy、并进行后处理等操作，得到最终带有检测框的图片结果，最后将结果保存到图片。最后记得释放相关资源，包括卸载模型、销毁输入输出数据集、释放 Context、释放指定的计算设备、以及AscendCL去初始化等操作。

3. **智能车实时视频推流延迟**  
   - 问题：HTTP 请求-响应模式导致延迟高。  
   - 解决方案：于延迟较高的问题，是因为HTTP 协议基于请求-响应模式，不是为实时流媒体设计的，推流过程中经常出现 1~3 秒甚至更高的延迟。通过降低视频分辨率、减少帧率（例如从 30fps 调整到 15fps）可以显著降低延迟。同时在局域网环境下比公网更稳定。在Python Flask或Django等框架中实现 HTTP 推流时，单线程下并发连接数量有限，当多个客户端同时请求时，容易出现阻塞或延迟增加。使用多线程或异步框架（如FastAPI、Tornado）提升并发能力。对视频帧进行统一缓存，多个客户端共享同一帧，避免重复解码。

4. **鸿蒙控制界面开发问题**  
   - 问题：ArkTS 框架、网络通信、性能优化适应。  
   - 解决方案：在鸿蒙控制界面开发过程中，主要遇到的问题集中在编程框架适应、网络通信以及性能优化上。由于鸿蒙采用 ArkTS 和声明式 UI，与传统 Android开发存在较大差异，初期在布局编写和事件绑定上有一定学习成本；在与小车端的通信中，HTTP 请求延迟较高，WebSocket 适合用于实时控制，但实现过程中需要解决长连接稳定性和权限配置问题；在性能方面，视频推流和控制逻辑若在同一线程执行容易造成界面卡顿，需要通过异步机制进行解耦。整体心得是：鸿蒙界面开发在交互逻辑和多端适配上具有优势，但需要开发者熟悉其新框架特性，并合理选择通信协议和架构设计，才能实现流畅、稳定的远程控制体验。
---

## 四、后续工作安排
1. **多传感器融合**  
   - 在现有摄像头基础上，增加激光雷达用于精确测距和建图，超声波传感器用于近距离障碍物检测。

2. **自动驾驶辅助功能**  
   - 自动巡航：利用激光雷达实现前车距离保持与速度控制。自动刹车/避障：通过多传感器检测障碍物并实时计算最优制动策略。

3. **智能路径规划与导航**  
   - 利用Dijkstra等算法进行全局路径规划，结合实时传感器数据进行局部路径调整，实现动态避障。

4. **远程监控与控制**  
   - 搭建小车端与云端通信模块（5G/Wi-Fi），实现数据上传和远程指令下发，在移动端提供实时视频流、状态数据和手动控制界面。
