🚗 基于 OrangePi AIpro 和鸿蒙系统的智能网联小车开发
一、项目信息
1. 项目名称

本项目名称为 基于 OrangePi AIpro 和鸿蒙系统的智能网联小车开发。
利用国产开发板及支持鸿蒙系统的移动终端开发智能网联小车，成为开发者快速掌握车联网开发的有效手段。本项目使用 OrangePi AIpro 开发板和高清摄像头搭建智能网联小车，为智能小车研究和开发提供实践平台。

2. 方案描述

本项目任务主要包括三部分：

🟢 目标识别模型训练与部署
在华为云平台 ModelArts 上使用 MindYOLO 训练目标识别模型，并将模型在 OrangePi AIpro 开发板上进行部署，实现对实时视频流的推理。

🟢 车道线检测与辅助控制
使用边缘检测算法提取每帧图像的边缘信息，实现车道线检测、车道偏移计算等辅助控制功能。

🟢 鸿蒙应用程序开发与远程控制
开发鸿蒙应用程序，实现控制者通过 Wi-Fi 远程控制智能网联小车运动，并将小车采集的视频数据实时传输到鸿蒙终端。

💡 效果示意（占位）：
<img src="https://via.placeholder.com/600x300?text=目标识别+车道线检测+视频回传" alt="示意图">

3. 时间规划
阶段	时间	工作内容
🟡 第一阶段	2025/7/1 - 2025/7/15	学习目标识别及车道检测算法，准备数据集与开发环境，熟悉 OrangePi AIpro 部署及鸿蒙开发
🟡 第二阶段	2025/7/16 - 2025/8/16	实现目标检测、车道检测与偏移量计算，并部署算法至 OrangePi AIpro，测试性能并优化
🟡 第三阶段	2025/8/17 - 2025/9/10	小车组件组装与控制测试，实现 Wi-Fi 远程控制和视频推流
🟡 第四阶段	2025/9/11 - 2025/9/18	开发鸿蒙终端应用，实现远程控制
🟡 第五阶段	2025/9/19 - 2025/9/28	小车功能联调与测试，完成结项报告
二、已完成工作
1. 🎯 目标识别模型训练

技术方案

数据集：COCO2017（训练集 118,287 张，验证集 5,000 张，80 类）

框架：MindSpore + MindYOLO

支持 YOLO 系列算法（YOLOv3~YOLOv8）

工作成果

模型：YOLOv5

步骤：

图像划分 → 网格化

边界框预测 → 位置 + 置信度 + 类别

CNN 单次前向传递

多任务损失函数训练

非最大抑制去除重复框

性能

标准 YOLO：每秒 45 帧

极速 YOLO：每秒 150 帧

延迟 <25ms，适合边缘部署

ModelArts 流程

登录 ModelArts → 创建 OBS 桶

上传数据集 → JupyterLab 训练

MindYOLO export → ONNX

ATC 转换 → OM 模型 → OrangePi AIpro 推理

💡 训练效果示意（占位）：
<img src="https://via.placeholder.com/600x300?text=目标检测训练效果" alt="目标检测训练效果">

2. 🛣️ 车道线检测

技术方案

使用 Canny 边缘检测算法

流程：灰度化 → 高斯滤波 → Sobel 梯度 → 非极大值抑制 → 双阈值 → 边缘连接

定义 ROI，仅保留道路区域

霍夫直线变换识别左右车道线

队列平滑多帧结果

工作成果

左右车道线用红色标记

稳定输出车道线信息

💡 车道线检测示意图：
<img src="https://via.placeholder.com/600x300?text=车道线检测示意" alt="车道线检测">

3. 🧭 车道偏移量计算

技术方案

车道中心 - 车辆中心 = 偏移量

符号：负值向左，正值向右

指令生成：

AL：向左微调

AR：向右微调

F：保持直行

工作成果

实时发送偏移量与指令（UDP）

示例：偏移量 32 → AR 指令

💡 偏移量示意图：
<img src="https://via.placeholder.com/600x200?text=车道偏移计算" alt="车道偏移">

4. 🖥️ OrangePi AIpro 模型部署

技术方案

输入预处理：RGB 640×640 → letterbox → HWC→CHW → float32

模型推理：InferSession.infer()，NPU 卷积与特征提取

后处理：NMS 去重，坐标映射回原图

可视化：PIL 绘制边框与中文标签

分类 & 结果发送（JSON via UDP）

工作成果

成功部署目标检测

实时识别行人、车辆

UDP 显示实时通信数据

💡 模型部署效果示意：
<img src="https://via.placeholder.com/600x300?text=模型部署实时检测" alt="模型部署效果">

5. 📱 基于鸿蒙的 UI 界面开发

技术方案

开发工具：DevEco Studio

语言：ArkTS (.ets)

特性：声明式 UI、状态管理、静态类型优化性能

工作成果

模块：

运动控制：前进/后退/左转/右转

舵机控制：摄像头/机械角度调节

速度调节：高/中/低

视频回传：实时画面

信息交互：UDP 显示数据

💡 UI 界面示意图：
<img src="https://via.placeholder.com/600x300?text=鸿蒙UI界面" alt="鸿蒙UI界面">

6. 🏗️ 智能网联车构造设计与模拟沙盘

技术方案

双层亚克力车体，模块化、轻量化

摄像头舵机可调，位于车头

主控板：OrangePi AIpro

电机与电池：底部安装，重心稳定

四轮差速 + 麦克纳木轮

沙盘模拟道路 + 行人/车辆模型

工作成果

完成车体搭建与沙盘实验

验证目标识别、车道线检测、车道保持功能

💡 智能车与沙盘示意图：
<img src="https://via.placeholder.com/600x300?text=智能车沙盘实验" alt="智能车沙盘">

三、遇到的问题及解决方案
⚠️ 问题	✅ 解决方案
MindYOLO 模型 ONNX 导出	SiLU 算子不被支持 → 自定义算子解决
AscendCL 接口未初始化	必须先初始化，推理完成后释放资源
实时视频推流延迟	降低分辨率/帧率，多线程/异步处理，视频帧共享
鸿蒙界面开发适应	熟悉 ArkTS & 声明式 UI，WebSocket 长连接，异步优化性能
四、后续工作安排

多传感器融合

增加激光雷达 → 精确测距与建图

超声波传感器 → 近距离障碍物检测

自动驾驶辅助功能

自动巡航：前车距离保持 & 速度控制

自动刹车/避障：实时计算最优制动策略

智能路径规划与导航

Dijkstra 全局规划 + 实时局部调整

动态避障

远程监控与控制

小车端 & 云端通信模块（5G/Wi-Fi）

移动端实时视频流、状态数据、手动控制

💡 未来规划示意：
<img src="https://via.placeholder.com/600x300?text=多传感器+路径规划+远程控制" alt="未来规划示意">
